{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build BERT Encoder\n",
    "Create a BERT encoder class which loads a pretrained Model. It tokenizes the text and converts it to a numerical encoding, this encoding along with attention mask is fed to the Softmax neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTEncoder(torch.nn.Module):\n",
    "    def __init__(self, max_length, pretrain_path):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            max_length: max length of sentence\n",
    "            pretrain_path: path of pretrain model\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.max_length = max_length\n",
    "        self.blank_padding = True\n",
    "        self.hidden_size = 768\n",
    "        self.bert = BertModel.from_pretrained(pretrain_path)\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(pretrain_path)\n",
    "\n",
    "    def forward(self, token, att_mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            token: (B, L), index of tokens\n",
    "            att_mask: (B, L), attention mask (1 for contents and 0 for padding)\n",
    "        Return:\n",
    "            (B, H), representations for sentences\n",
    "        \"\"\"\n",
    "        _, x = self.bert(token, attention_mask=att_mask)\n",
    "        return x\n",
    "\n",
    "    def tokenize(self, item):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            item: data instance containing 'token', 'h' and 't'\n",
    "        Return:\n",
    "            Name of the relation of the sentence\n",
    "        \"\"\"\n",
    "        # Sentence -> token\n",
    "        if 'token' not in item:\n",
    "            raise Exception('Check your input parameters')\n",
    "\n",
    "        sentence = item['token']\n",
    "        pos_head = item['h']['pos']\n",
    "        pos_tail = item['t']['pos']\n",
    "\n",
    "        pos_min = pos_head\n",
    "        pos_max = pos_tail\n",
    "        if pos_head[0] > pos_tail[0]:\n",
    "            pos_min = pos_tail\n",
    "            pos_max = pos_head\n",
    "            rev = True\n",
    "        else:\n",
    "            rev = False\n",
    "        \n",
    "        sent_left = self.tokenizer.tokenize(' '.join(sentence[:pos_min[0]]))\n",
    "        ent0 = self.tokenizer.tokenize(' '.join(sentence[pos_min[0]:pos_min[1]]))\n",
    "        sent_middle = self.tokenizer.tokenize(' '.join(sentence[pos_min[1]:pos_max[0]]))\n",
    "        ent1 = self.tokenizer.tokenize(' '.join(sentence[pos_max[0]:pos_max[1]]))\n",
    "        sent_right = self.tokenizer.tokenize(' '.join(sentence[pos_max[1]:]))\n",
    "\n",
    "        ent0 = ['[unused0]'] + ent0 + ['[unused1]'] if not rev else ['[unused2]'] + ent0 + ['[unused3]']\n",
    "        ent1 = ['[unused2]'] + ent1 + ['[unused3]'] if not rev else ['[unused0]'] + ent1 + ['[unused1]']\n",
    "\n",
    "        re_tokens = ['[CLS]'] + sent_left + ent0 + sent_middle + ent1 + sent_right + ['[SEP]']\n",
    "#         print('re_tokens', re_tokens)\n",
    "        indexed_tokens = self.tokenizer.convert_tokens_to_ids(re_tokens)\n",
    "        avai_len = len(indexed_tokens)\n",
    "\n",
    "        # Padding\n",
    "        if self.blank_padding:\n",
    "            while len(indexed_tokens) < self.max_length:\n",
    "                indexed_tokens.append(0)  # 0 is id for [PAD]\n",
    "            indexed_tokens = indexed_tokens[:self.max_length]\n",
    "        indexed_tokens = torch.tensor(indexed_tokens).long().unsqueeze(0)  # (1, L)\n",
    "\n",
    "        # Attention mask\n",
    "        att_mask = torch.zeros(indexed_tokens.size()).long()  # (1, L)\n",
    "        att_mask[0, :avai_len] = 1\n",
    "        return indexed_tokens, att_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Softmax Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxNN(torch.nn.Module):\n",
    "    def __init__(self, sentence_encoder, rel2id):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sentence_encoder: encoder for sentences\n",
    "            id2rel: dictionary of id -> relation name mapping\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.sentence_encoder = sentence_encoder\n",
    "        self.num_class = len(rel2id)\n",
    "        self.fc = torch.nn.Linear(self.sentence_encoder.hidden_size,self.num_class)\n",
    "        self.softmax = torch.nn.Softmax(-1)\n",
    "        self.rel2id = rel2id\n",
    "        self.id2rel = {}\n",
    "        self.drop = torch.nn.Dropout()\n",
    "        for rel, id in rel2id.items():\n",
    "            self.id2rel[id] = rel\n",
    "\n",
    "    def infer(self, item):\n",
    "        self.eval()\n",
    "        _item = self.sentence_encoder.tokenize(item)\n",
    "        item = []\n",
    "        for x in _item:\n",
    "            item.append(x.to(next(self.parameters()).device))\n",
    "        logits = self.forward(*item)\n",
    "        logits = self.softmax(logits)\n",
    "        score, pred = logits.max(-1)\n",
    "        score = score.item()\n",
    "        pred = pred.item()\n",
    "        return self.id2rel[pred], score\n",
    "    \n",
    "    def forward(self, *args):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            args: depends on the encoder\n",
    "        Return:\n",
    "            logits, (B, N)\n",
    "        \"\"\"\n",
    "        rep = self.sentence_encoder(*args) # (B, H)\n",
    "        rep = self.drop(rep)\n",
    "        logits = self.fc(rep) # (B, N)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_bert_wiki80():\n",
    "    model_name = 'wiki80_bert_softmax'\n",
    "    rel2id = json.load(open('./benchmark/wiki80/wiki80_rel2id.json'))\n",
    "    sentence_encoder = BERTEncoder(\n",
    "        max_length=80, pretrain_path='./pretrain/bert-base-uncased')\n",
    "    model = SoftmaxNN(sentence_encoder, rel2id)\n",
    "    ckpt = './pretrain/nre/wiki80_bert_softmax.pth.tar'\n",
    "    model.load_state_dict(torch.load(ckpt, map_location='cpu')['state_dict'])        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model_bert_wiki80()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'He was the son of Mael Duin mac Maele Fithrich, and grandson of the high king aed Uaridnach (died 612).'\n",
    "tokens = word_tokenize(text)\n",
    "for i in range(len(tokens)):\n",
    "    print(i, tokens[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.infer({'token': tokens, 'h': {'pos': (5, 10)}, 't': {'pos': (17,19)}})\n",
    "print(result)\n",
    "\n",
    "#Check if model is correctly working\n",
    "if result[0] != 'father':\n",
    "    raise Exception('Not father')\n",
    "if result[1] < 0.69:\n",
    "    raise Exception('Accuracy drop')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "569a",
   "language": "python",
   "name": "569a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
